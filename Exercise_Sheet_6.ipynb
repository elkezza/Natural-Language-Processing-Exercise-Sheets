{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## Exercise Sheet 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package ppattach to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package ppattach is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports for all exercises\n",
    "import nltk\n",
    "import random\n",
    "import pickle\n",
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier, classify, FreqDist\n",
    "from nltk.classify import apply_features, accuracy\n",
    "from nltk.corpus import names, senseval, brown, movie_reviews, ppattach\n",
    "from nltk.tag import untag\n",
    "from random import shuffle\n",
    "nltk.download('ppattach')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a name gender classifier using the Names Corpus, the `apply_features` function, shuffling, and a test set of 500 instances. Use the following features:\n",
    "\n",
    "a) first letter;  \n",
    "b) last letter;  \n",
    "c) last two letters;  \n",
    "d) length;  \n",
    "e) for each letter one feature, which is true if the name contains the letter.\n",
    "\n",
    "Use the `NaiveBayesClassifier`, calculate the accuracy, and display the 10 most informative features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.774\n",
      "Most Informative Features\n",
      "        last_two_letters = 'na'           female : male   =    166.6 : 1.0\n",
      "        last_two_letters = 'la'           female : male   =     76.0 : 1.0\n",
      "        last_two_letters = 'ia'           female : male   =     39.9 : 1.0\n",
      "             last_letter = 'a'            female : male   =     36.6 : 1.0\n",
      "        last_two_letters = 'sa'           female : male   =     34.3 : 1.0\n",
      "        last_two_letters = 'ta'           female : male   =     32.4 : 1.0\n",
      "             last_letter = 'k'              male : female =     32.0 : 1.0\n",
      "        last_two_letters = 'us'             male : female =     28.1 : 1.0\n",
      "        last_two_letters = 'rd'             male : female =     26.3 : 1.0\n",
      "        last_two_letters = 'ra'           female : male   =     25.6 : 1.0\n",
      "The name Neo is predicted to be: male\n"
     ]
    }
   ],
   "source": [
    "# Feature extractor function for names\n",
    "# Here we define a feature extractor function, gender_features, \n",
    "# that takes a name as input and creates a dictionary of features. \n",
    "# These features include the first and last letters of the name, \n",
    "# the last two letters, the length of the name, and whether each letter of the alphabet is in the name.\n",
    "\n",
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    features[\"last_two_letters\"] = name[-2:].lower()\n",
    "    features[\"length\"] = len(name)\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[f\"contains({letter})\"] = (letter in name.lower())\n",
    "    return features\n",
    "\n",
    "# Prepare the data\n",
    "names_genders_list_of_pair = [(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')]\n",
    "random.shuffle(names_genders_list_of_pair)\n",
    "\n",
    "# Extract features\n",
    "    # Iterates through each (name, gender) pair in the names list.\n",
    "    # For each pair, it applies the gender_features function to the name to create a features dictionary and pairs it with the gender label.\n",
    "featuresets = [(gender_features(name), gender) for (name, gender) in names_genders_list_of_pair]\n",
    "\n",
    "# Split into training and test sets\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "    # Creates a Naive Bayes classifier.\n",
    "    # The NaiveBayesClassifier.train method takes the train_set as input and creates a model that associates the features with the gender label.\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Accuracy:\", nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "# Show the most informative features\n",
    "classifier.show_most_informative_features(10)\n",
    "\n",
    "\n",
    "\n",
    "# Now you can use the classifier to predict a new name\n",
    "name = \"Neo\"\n",
    "print(f\"The name {name} is predicted to be: {classifier.classify(gender_features(name))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The Senseval 2 Corpus contains data intended to train word-sense disambiguation classifiers. Using this dataset, build a `NaiveBayesClassifier` that predicts the correct sense tag for a given instance for the word \"hard\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import senseval\n",
    "instances = senseval.instances('hard.pos')\n",
    "labeled_instances = [(inst, inst.senses) for inst in instances] \n",
    "size = int(len(labeled_instances) * 0.1)\n",
    "random.shuffle(labeled_instances)\n",
    "train_set = apply_features(features, labeled_instances[size:])\n",
    "test_set = apply_features(features, labeled_instances[:size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the preceding and following word as features. They can be calculated by retrieving the position of the word \"hard\" as `p=inst.position` and then accessing `inst.context[p-1]` and `inst.context[p+1]`.\n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the individual accuracies. Finally, print the average accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal:\n",
    "We want to determine in which sense (meaning) of a words is used in sentence, when a word has more than meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Accuracy: 0.9122\n",
      "Iteration 2 Accuracy: 0.8961\n",
      "Iteration 3 Accuracy: 0.8961\n",
      "Iteration 4 Accuracy: 0.8915\n",
      "Iteration 5 Accuracy: 0.8891\n",
      "Iteration 6 Accuracy: 0.8915\n",
      "Iteration 7 Accuracy: 0.9376\n",
      "Iteration 8 Accuracy: 0.9284\n",
      "Iteration 9 Accuracy: 0.9400\n",
      "Iteration 10 Accuracy: 0.8661\n",
      "Average Accuracy: 0.9048\n"
     ]
    }
   ],
   "source": [
    "# 'senseval' is a corpus from NLTK specifically designed for word-sense disambiguation tasks\n",
    "# Function to extract features from the instances\n",
    "   # Extracts the context words around the target word \"hard\" in a given instance from the Senseval corpus.\n",
    "def features(instance):\n",
    "    p = instance.position\n",
    "    # dictionary features where it conditionally adds the preceding and following words of \"hard\" \n",
    "    # if they exist (i.e., \"hard\" is not the first or last word).\n",
    "    features = {}\n",
    "    if p > 0:\n",
    "        features['preceding_word'] = instance.context[p - 1]\n",
    "    if p < len(instance.context) - 1:\n",
    "        features['following_word'] = instance.context[p + 1]\n",
    "    return features\n",
    "\n",
    "# Load instances for the word \"hard\"\n",
    "    # Loads all instances of the word \"hard\" from the Senseval corpus.\n",
    "    # labeled_instances is a list of tuples where each tuple contains an instance and its correct sense labels.\n",
    "instances = senseval.instances('hard.pos')\n",
    "labeled_instances = [(inst, inst.senses) for inst in instances]\n",
    "\n",
    "# Variable to store the sum of accuracies for calculating the average\n",
    "accuracy_sum = 0\n",
    "\n",
    "# Perform 10 iterations of shuffling and classification\n",
    "    # a loop that will run 10 times, each time shuffling the data and testing the classifier.\n",
    "for i in range(10):\n",
    "    # Shuffle the labeled instances\n",
    "    random.shuffle(labeled_instances)\n",
    "    \n",
    "    # Split the data into training and test sets (10% for test)\n",
    "        # Determines the size of the test set to be 10% of the full dataset.\n",
    "        # The data is split into training and test sets based on that size.\n",
    "    size = int(len(labeled_instances) * 0.1)\n",
    "    train_set, test_set = labeled_instances[size:], labeled_instances[:size]\n",
    "    \n",
    "    # Convert instances to feature sets\n",
    "         # Converts the training and testing data into a format usable by the classifier, \n",
    "         # where each instance is a pair of the feature dictionary and the correct sense.\n",
    "    train_set = [(features(n), sense) for (n, sense) in train_set]\n",
    "    test_set = [(features(n), sense) for (n, sense) in test_set]\n",
    "    \n",
    "    # Train the Naive Bayes classifier\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "    \n",
    "    # Calculate the accuracy of the classifier\n",
    "    current_accuracy = accuracy(classifier, test_set)\n",
    "    accuracy_sum += current_accuracy\n",
    "    \n",
    "    # Print the accuracy for the current iteration\n",
    "    print(f\"Iteration {i+1} Accuracy: {current_accuracy:.4f}\")\n",
    "\n",
    "# Print the average accuracy\n",
    "print(f\"Average Accuracy: {accuracy_sum/10:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.8660508083140878\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD3',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD2',) Actual sense: ('HARD2',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD3',) Actual sense: ('HARD1',)\n",
      "Predicted sense: ('HARD1',) Actual sense: ('HARD1',)\n"
     ]
    }
   ],
   "source": [
    "# Test the classifier\n",
    "accuracy = classify.accuracy(classifier, test_set)\n",
    "print(\"Accuracy on the test set:\", accuracy)\n",
    "\n",
    "# Optionally, you can print out the predictions for the instances in the test set\n",
    "for test_instance in test_set:\n",
    "    features, label = test_instance\n",
    "    predicted_label = classifier.classify(features)\n",
    "    print('Predicted sense:', predicted_label, 'Actual sense:', label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "The synonyms \"strong\" and \"powerful\" pattern differently. Use the tagged Brown corpus with the universal tagset to first list the nouns which follow \"strong\" vs. \"powerful\". Write for this a function `next_noun(word, tagged_text)` which returns the list of nouns that follow `word` in the `tagged_text`. Build then a `NaiveBayesClassifier` that predicts when each word should be used by using the function `apply_features` and the following noun as single feature.\n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the individual accuracies. Finally, print the average accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Accuracy = 0.50\n",
      "Iteration 2: Accuracy = 0.86\n",
      "Iteration 3: Accuracy = 0.93\n",
      "Iteration 4: Accuracy = 0.57\n",
      "Iteration 5: Accuracy = 0.57\n",
      "Iteration 6: Accuracy = 0.71\n",
      "Iteration 7: Accuracy = 0.93\n",
      "Iteration 8: Accuracy = 0.64\n",
      "Iteration 9: Accuracy = 0.57\n",
      "Iteration 10: Accuracy = 0.79\n",
      "Average Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.classify import accuracy as nltk_accuracy  # renamed to avoid conflicts\n",
    "\n",
    "# Define next_noun, a function that finds all instances of a specified word (converted to lowercase) \n",
    "# in the tagged_text and returns the noun that immediately follows it.\n",
    "def next_noun(word, tagged_text):\n",
    "    return [tagged_text[i+1][0] for i, (w, tag) in enumerate(tagged_text) \n",
    "            if w.lower() == word and i < len(tagged_text)-1 and tagged_text[i+1][1] == 'NOUN']\n",
    "\n",
    "# Fetch all the tagged words from the Brown corpus using the 'universal' tagset, \n",
    "# which is a simplified tagset that has general tags like 'NOUN', 'VERB', etc.\n",
    "tagged_words = brown.tagged_words(tagset='universal')\n",
    "\n",
    "# Create a list of feature sets. Each feature set is a tuple \n",
    "    # where the first element is a dictionary with a single key-value pair: the key is 'next-word' \n",
    "        # and the value is the noun following either 'strong' or 'powerful'. \n",
    "# The second element of the tuple is the label (either 'strong' or 'powerful').\n",
    "featuresets = [( {'next-word': noun}, word ) \n",
    "               for word in ('strong', 'powerful') \n",
    "               for noun in next_noun(word, tagged_words)]\n",
    "\n",
    "# Set the number of iterations for the experiment to 10 \n",
    "num_iterations = 10\n",
    "# initialize a variable to sum the accuracies across all iterations.\n",
    "sum_accuracy = 0\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    random.shuffle(featuresets)  # Shuffle the featuresets to ensure randomness.\n",
    "    size = int(len(featuresets) * 0.1) #Calculate 10% of the total number of feature sets for use as the test set size.\n",
    "    train_set, test_set = featuresets[size:], featuresets[:size] # Split the data into a training set (90%) and a test set (10%).\n",
    "    classifier = NaiveBayesClassifier.train(train_set) # Train the Naive Bayes classifier on the training set.\n",
    "    # Measure and print the accuracy of the classifier on the test set.\n",
    "    current_accuracy = nltk_accuracy(classifier, test_set)  # use the renamed function\n",
    "    sum_accuracy += current_accuracy\n",
    "    print(f\"Iteration {iteration+1}: Accuracy = {current_accuracy:.2f}\")\n",
    "\n",
    "average_accuracy = sum_accuracy / num_iterations\n",
    "print(f\"Average Accuracy: {average_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Based on the Movie Reviews document classifier discussed in this chapter, build a new `NaiveBayesClassifier`. Tag first the Movie Reviews Corpus using the combined tagger from the previous chapter stored in `t2.pkl`. Filter the tagged words to contain only words for the tags `['JJ', 'JJR', 'JJS', 'RB', 'NN', 'NNS', 'VB', 'VBN', 'VBG', 'VBZ', 'VBD', 'QL']` as well as only alphabetic tokens with at least three characters. Convert the words to lowercase. Use the most common 5000 words as `word_features` in the function `document_features`. \n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the accuracy and 5 most informative features for each iteration. Finally, print the average accuracy.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "input = open('t2.pkl', 'rb')\n",
    "tagger = load(input)\n",
    "input.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Accuracy = 0.78\n",
      "Most Informative Features\n",
      "     contains(ludicrous) = True              neg : pos    =     14.4 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     13.1 : 1.0\n",
      "        contains(elliot) = True              pos : neg    =     10.4 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =     10.2 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.1 : 1.0\n",
      "Iteration 2: Accuracy = 0.83\n",
      "Most Informative Features\n",
      "     contains(ludicrous) = True              neg : pos    =     15.1 : 1.0\n",
      "     contains(stupidity) = True              neg : pos    =     10.7 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =      9.9 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =      9.8 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =      9.1 : 1.0\n",
      "Iteration 3: Accuracy = 0.83\n",
      "Most Informative Features\n",
      "     contains(insulting) = True              neg : pos    =     16.4 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     14.2 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     12.7 : 1.0\n",
      "       contains(idiotic) = True              neg : pos    =     12.2 : 1.0\n",
      "        contains(turkey) = True              neg : pos    =     11.8 : 1.0\n",
      "Iteration 4: Accuracy = 0.85\n",
      "Most Informative Features\n",
      "     contains(stupidity) = True              neg : pos    =     19.7 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     12.7 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.6 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =      9.6 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =      9.0 : 1.0\n",
      "Iteration 5: Accuracy = 0.76\n",
      "Most Informative Features\n",
      "        contains(turkey) = True              neg : pos    =     11.5 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     10.8 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.6 : 1.0\n",
      "          contains(taxi) = True              pos : neg    =     10.3 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =      9.9 : 1.0\n",
      "Iteration 6: Accuracy = 0.81\n",
      "Most Informative Features\n",
      "      contains(poignant) = True              pos : neg    =     10.7 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     10.5 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.5 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =     10.2 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =      9.8 : 1.0\n",
      "Iteration 7: Accuracy = 0.81\n",
      "Most Informative Features\n",
      "    contains(schumacher) = True              neg : pos    =     11.1 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.7 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     10.5 : 1.0\n",
      "       contains(freddie) = True              neg : pos    =      9.8 : 1.0\n",
      "        contains(hudson) = True              neg : pos    =      9.8 : 1.0\n",
      "Iteration 8: Accuracy = 0.84\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     11.1 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.3 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.0 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =      9.9 : 1.0\n",
      "         contains(mulan) = True              pos : neg    =      8.9 : 1.0\n",
      "Iteration 9: Accuracy = 0.80\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     11.9 : 1.0\n",
      "     contains(stupidity) = True              neg : pos    =     11.3 : 1.0\n",
      "     contains(insulting) = True              neg : pos    =     10.2 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.1 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =      9.8 : 1.0\n",
      "Iteration 10: Accuracy = 0.74\n",
      "Most Informative Features\n",
      "        contains(seagal) = True              neg : pos    =     12.9 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     10.4 : 1.0\n",
      "          contains(taxi) = True              pos : neg    =     10.4 : 1.0\n",
      "     contains(marvelous) = True              pos : neg    =     10.2 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =      9.6 : 1.0\n",
      "Average Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Load the combined tagger\n",
    "with open('t2.pkl', 'rb') as f:\n",
    "    tagger = pickle.load(f)\n",
    "\n",
    "# Function to filter the tagged words and convert to lowercase\n",
    " # takes a list of tagged_words and a list of allowed_word_types. \n",
    "    # It filters the words by ensuring they are of the allowed POS tags, are purely alphabetical (no numbers or symbols), \n",
    "        # and are at least three characters long. The filtered words are then converted to lowercase.\n",
    "def filter_words(tagged_words, allowed_word_types):\n",
    "    return [\n",
    "        word.lower() for word, tag in tagged_words\n",
    "        if tag in allowed_word_types and word.isalpha() and len(word) >= 3\n",
    "    ]\n",
    "\n",
    "# Function to determine the set of contained word features in a document\n",
    "    # creates a feature set for a given document. \n",
    "        # The features are boolean values indicating whether each word in a predetermined list (word_features) is present in the document. \n",
    "def document_features(document, word_features):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[f'contains({word})'] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "# Allowed word types\n",
    "    # defines the list of POS tags that are permitted for inclusion in the analysis.\n",
    "        # These tags correspond to adjectives, adverbs, nouns, and various verb forms.\n",
    "allowed_word_types = ['JJ', 'JJR', 'JJS', 'RB', 'NN', 'NNS', 'VB', 'VBN', 'VBG', 'VBZ', 'VBD', 'QL']\n",
    "\n",
    "# Tag the Movie Reviews Corpus and filter words\n",
    "    # iterate over each file in the movie reviews corpus, tag each word in the reviews with the POS tagger, \n",
    "        #filter the tagged words using the filter_words function, \n",
    "            # and then pair the result with the corresponding category (positive or negative).\n",
    "tagged_reviews = [(filter_words(tagger.tag(movie_reviews.words(fileid)), allowed_word_types), category)\n",
    "                  for category in movie_reviews.categories()\n",
    "                  for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# Obtain the 5000 most common words\n",
    "    # A FreqDist (Frequency Distribution) is created for all words in the corpus that are alphabetical and at least three characters long. \n",
    "        # The 5000 most common words are extracted to be used as features.\n",
    "all_words = FreqDist(word.lower() for word in movie_reviews.words() if word.isalpha() and len(word) >= 3)\n",
    "word_features = list(all_words)[:5000]\n",
    "\n",
    "# Shuffle and create the feature sets\n",
    "random.shuffle(tagged_reviews)\n",
    "featuresets = [(document_features(words, word_features), category) for (words, category) in tagged_reviews]\n",
    "\n",
    "# Run 10 iterations\n",
    "sum_accuracy = 0\n",
    "#The list of tagged reviews is shuffled to ensure that we get a random distribution of \n",
    "    # data when we later split this into training and testing sets. \n",
    "        # Feature sets are created for each document using the document_features function.\n",
    "for i in range(10):\n",
    "    random.shuffle(featuresets)\n",
    "    size = int(len(featuresets) * 0.1)\n",
    "    train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "    current_accuracy = nltk_accuracy(classifier, test_set)\n",
    "    sum_accuracy += current_accuracy\n",
    "    print(f\"Iteration {i+1}: Accuracy = {current_accuracy:.2f}\")\n",
    "    classifier.show_most_informative_features(5)\n",
    "\n",
    "# Calculate and print the average accuracy\n",
    "average_accuracy = sum_accuracy / 10\n",
    "print(f\"Average Accuracy: {average_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "The PP Attachment Corpus is a corpus describing prepositional phrase attachment decisions. Each instance in the training corpus is encoded as a `PPAttachment` object:\n",
    "\n",
    "    from nltk.corpus import ppattach\n",
    "    ppattach.attachments('training')\n",
    "    \n",
    "        [PPAttachment(sent='0', verb='join', noun1='board',\n",
    "            prep='as', noun2='director', attachment='V'),\n",
    "        PPAttachment(sent='1', verb='is', noun1='chairman',\n",
    "            prep='of', noun2='N.V.', attachment='N'),\n",
    "        ...]\n",
    "\n",
    "    inst = ppattach.attachments('training')[1]\n",
    "    (inst.noun1, inst.prep, inst.noun2)\n",
    "    \n",
    "        ('chairman', 'of', 'N.V.')\n",
    "\n",
    "In the same way, `ppattach.attachments('test')` accesses the test instances. Select only the instances where `inst.attachment` is `'N'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import ppattach\n",
    "nattach = [inst for inst in ppattach.attachments('training')\n",
    "               if inst.attachment == 'N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this sub-corpus, build a `NaiveBayesClassifier` that attempts to predict which preposition is used to connect a given pair of nouns. For example, given the pair of nouns \"team\" and \"researchers\", the classifier should predict the preposition \"of\". \n",
    "\n",
    "Write for this purpose a function `prepare_featuresets(subcorpus)`, where `subcorpus` is either the string \"training\" or \"test\" to return the training set or the test set. \n",
    "\n",
    "Print the achieved accuracy as well as the result of `classifier.classify({ 'noun1': 'team', 'noun2': 'researchers' })`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57\n",
      "Predicted preposition for ('team', 'researchers'): of\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Function to filter instances where attachment is 'N'\n",
    "    # creating a list comprehension that iterates over all instances in the training set of the PP Attachment Corpus. \n",
    "    # It filters the instances to include only those where the attachment is 'N', \n",
    "        # which indicates that the prepositional phrase is attached to a noun.\n",
    "def filter_n_attachments(subcorpus_name):\n",
    "    return [inst for inst in ppattach.attachments(subcorpus_name)\n",
    "            if inst.attachment == 'N']\n",
    "\n",
    "# Step 3: Function to prepare the feature sets\n",
    "    # takes a subcorpus argument ('training' or 'test') and prepares the feature sets for the classifier. \n",
    "    # It first gets the relevant subset of the corpus, \n",
    "        # then creates feature dictionaries for each instance (only for those with 'N' attachment), \n",
    "            # mapping the pair of nouns to the preposition used.\n",
    "def prepare_featuresets(subcorpus_name):\n",
    "    attachments = filter_n_attachments(subcorpus_name)\n",
    "    featuresets = []\n",
    "    for inst in attachments:\n",
    "        features = {'noun1': inst.noun1, 'noun2': inst.noun2}\n",
    "        preposition = inst.prep\n",
    "        featuresets.append((features, preposition))\n",
    "    return featuresets\n",
    "\n",
    "# Prepare the training and test sets\n",
    "training_set = prepare_featuresets('training')\n",
    "test_set = prepare_featuresets('test')\n",
    "\n",
    "# Step 4: Train the Naive Bayes Classifier\n",
    "classifier = NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "# Step 5: Evaluate the classifier's accuracy and test with a given noun pair\n",
    "print(f\"Accuracy: {nltk_accuracy(classifier, test_set):.2f}\")\n",
    "predicted_prep = classifier.classify({'noun1': 'team', 'noun2': 'researchers'})\n",
    "print(f\"Predicted preposition for ('team', 'researchers'): {predicted_prep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reference:\n",
    "- https://www.nltk.org/howto/corpus.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
